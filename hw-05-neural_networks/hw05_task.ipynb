{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diatlova_hw05_task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qp0H_zUQuu_"
      },
      "source": [
        "# Нейронные сети\n",
        "__Суммарное количество баллов: 10__\n",
        "\n",
        "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
        "\n",
        "__Тема письма: `[ML][HW05] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
        "\n",
        "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22ezVRf3QuvA"
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "from sklearn.datasets import make_blobs, make_moons\n",
        "from typing import List, NoReturn"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qfDPH_LQuvF"
      },
      "source": [
        "### Задание 1 (3 балла)\n",
        "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
        "\n",
        "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
        "\n",
        "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
        "\n",
        "`Softmax` - слой, соответствующий функции активации [softmax](https://ru.wikipedia.org/wiki/Softmax)\n",
        "\n",
        "\n",
        "#### Методы\n",
        "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
        "\n",
        "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
        "\n",
        "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWFLlHqaYbgC"
      },
      "source": [
        "class Module:\n",
        "    \"\"\"\n",
        "    Абстрактный класс. Его менять не нужно.\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def backward(self, d):\n",
        "        raise NotImplementedError()\n",
        "        \n",
        "    def update(self, alpha):\n",
        "        pass"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYS2gE4PYepZ"
      },
      "source": [
        "class Linear(Module):\n",
        "    \"\"\"\n",
        "    Линейный полносвязный слой.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        in_features : int\n",
        "            Размер входа.\n",
        "        out_features : int \n",
        "            Размер выхода.\n",
        "    \n",
        "        Notes\n",
        "        -----\n",
        "        W и b инициализируются случайно.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "в\n",
        "    \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = Wx + b.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "            То есть, либо x вектор с in_features элементов,\n",
        "            либо матрица размерности (batch_size, in_features).\n",
        "    \n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя.\n",
        "            Либо вектор с out_features элементами,\n",
        "            либо матрица размерности (batch_size, out_features)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.x = x.copy()\n",
        "        y = self.x @ self.w + self.b\n",
        "        return y \n",
        "\n",
        "    \n",
        "    def backward(self, d: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        #dl / dx - return; dl / db - save; dl / dw - save; dl / dy - have\n",
        "        db_sum = self.x.shape[0]\n",
        "        self.db = np.sum(d, axis=0)  / db_sum\n",
        "\n",
        "        dx = d @ self.w.T \n",
        "        self.dw = self.x.T @ d / db_sum\n",
        "\n",
        "        return dx\n",
        "\n",
        "\n",
        "    def update(self, alpha: float) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обновляет W и b с заданной скоростью обучения.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        alpha : float\n",
        "            Скорость обучения.\n",
        "        \"\"\"\n",
        "\n",
        "        self.w = self.w - (alpha * self.dw)\n",
        "        self.b = self.b - (alpha * self.db)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94hkbnD1QuvG"
      },
      "source": [
        "class ReLU(Module):\n",
        "    \"\"\"\n",
        "    Слой, соответствующий функции активации ReLU.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.x = None\n",
        "    \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        \"\"\"\n",
        "        Возвращает y = max(0, x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "    \n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        self.x = x.copy()\n",
        "        y = np.maximum(x, np.zeros_like(x))\n",
        "        return y\n",
        "        \n",
        "    def backward(self, d) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "        # dl / dy - have; dl / dx - return\n",
        "        dy_x = np.where(self.x <= 0, 0, 1)\n",
        "        dx = d * dy_x\n",
        "        return dx\n",
        "        \n",
        "class Softmax(Module):\n",
        "    \"\"\"\n",
        "    Слой, соответствующий функции активации Softmax.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.x = None\n",
        "        self.y = None\n",
        "        \n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Возвращает y = Softmax(x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной вектор или батч.\n",
        "    \n",
        "        Return\n",
        "        ------\n",
        "        y : np.ndarray\n",
        "            Выход после слоя (той же размерности, что и вход).\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        self.x = x.copy()\n",
        "\n",
        "        def func(x):\n",
        "          max_element = np.amax(x)\n",
        "          return np.exp(x - max_element) / np.sum(np.exp(x - max_element))         \n",
        "\n",
        "        if len(x.shape) == 1:\n",
        "          self.y = func(x)\n",
        "          return self.y\n",
        "\n",
        "        else:\n",
        "          self.y = np.apply_along_axis(func, 1, self.x)\n",
        "          return self.y    \n",
        "        \n",
        "    def backward(self, d) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Cчитает градиент при помощи обратного распространения ошибки.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        d : np.ndarray\n",
        "            Градиент.\n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Новое значение градиента.\n",
        "        \"\"\"\n",
        "\n",
        "        dx = self.y - d\n",
        "        return dx"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb_ip_h8QuvJ"
      },
      "source": [
        "### Задание 2 (2 балла)\n",
        "Теперь сделаем саму нейронную сеть.\n",
        "\n",
        "#### Методы\n",
        "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
        "\n",
        "#### Параметры конструктора\n",
        "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
        "\n",
        "`epochs` - количество эпох обучения\n",
        "\n",
        "`alpha` - скорость обучения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_JFCizKQuvK"
      },
      "source": [
        "class MLPClassifier:\n",
        "    def __init__(self, modules: List[Module], epochs: int = 40, alpha: float = 0.01):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        modules : List[Module]\n",
        "            Cписок, состоящий из ранее реализованных модулей и \n",
        "            описывающий слои нейронной сети. \n",
        "            В конец необходимо добавить Softmax.\n",
        "        epochs : int\n",
        "            Количество эпох обученияю\n",
        "        alpha : float\n",
        "            Cкорость обучения.\n",
        "        \"\"\"\n",
        "\n",
        "        self.modules = modules\n",
        "        self.modules.append(Softmax())\n",
        "        self.epochs = epochs\n",
        "        self.alpha = alpha\n",
        "            \n",
        "    def fit(self, X: np.ndarray, y: np.ndarray, batch_size=32) -> NoReturn:\n",
        "        \"\"\"\n",
        "        Обучает нейронную сеть заданное число эпох. \n",
        "        В каждой эпохе необходимо использовать cross-entropy loss для обучения, \n",
        "        а так же производить обновления не по одному элементу, а используя батчи.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для обучения.\n",
        "        y : np.ndarray\n",
        "            Вектор меток классов для данных.\n",
        "        batch_size : int\n",
        "            Размер батча.\n",
        "        \"\"\"\n",
        "\n",
        "        classes = np.unique(y)\n",
        "        classes = len(classes)\n",
        "        y_ = np.zeros((len(y), classes))\n",
        "        for i in range(len(y)):\n",
        "          pos = y[i]\n",
        "          y_[i][pos] = 1    \n",
        "        for epoch in range(self.epochs):       \n",
        "          stop = X.shape[0]\n",
        "          for i in range(0, stop, batch_size):\n",
        "            if i + batch_size <= stop:\n",
        "              borders = y_[i:i+batch_size]\n",
        "              param = X[i:i+batch_size]  \n",
        "            else:  \n",
        "              param = X[i:stop]\n",
        "              borders = y_[i:stop]\n",
        "            for module in self.modules: \n",
        "              param = module.forward(param)                \n",
        "            for module in reversed(self.modules):\n",
        "              borders = module.backward(borders)\n",
        "              module.update(self.alpha)\n",
        "            \n",
        "        \n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказывает вероятности классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Предсказанные вероятности классов для всех элементов X.\n",
        "            Размерность (X.shape[0], n_classes)\n",
        "        \n",
        "        \"\"\"\n",
        "        p = X.copy()\n",
        "        for module in self.modules:         \n",
        "          p = module.forward(p)             \n",
        "        return p\n",
        "        \n",
        "    def predict(self, X) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Предсказывает метки классов для элементов X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.ndarray\n",
        "            Данные для предсказания.\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        np.ndarray\n",
        "            Вектор предсказанных классов\n",
        "        \n",
        "        \"\"\"\n",
        "        p = self.predict_proba(X)\n",
        "        return np.argmax(p, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZhRZBccSqKB",
        "outputId": "91ecdcef-f2ad-4bdc-84d4-b3986f19bdc6"
      },
      "source": [
        "np.seterr(over=\"raise\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onDymYQXQuvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd82e5e-aee2-4f7e-e31e-85af8616f795"
      },
      "source": [
        "p = MLPClassifier([\n",
        "    Linear(4, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 64),\n",
        "    ReLU(),\n",
        "    Linear(64, 2)\n",
        "])\n",
        "\n",
        "X = np.random.randn(50, 4)\n",
        "\n",
        "y = [(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X]\n",
        "\n",
        "p.fit(X, y)\n",
        "p.predict(X)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJxVHO8vUFk2",
        "outputId": "dd589374-cdff-4494-cfca-d2c1ad479f28"
      },
      "source": [
        "np.count_nonzero(y == p.predict(X)) / len(y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C1EIsDqQuvQ"
      },
      "source": [
        "### Задание 3 (2 балла)\n",
        "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
        "\n",
        "#### Оценка\n",
        "Accuracy на первом датасете больше 0.85 - +1 балл\n",
        "\n",
        "Accuracy на втором датасете больше 0.85 - +1 балл"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UAgXTcQuvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fcded60-6675-488d-d203-3c43ed8fd98d"
      },
      "source": [
        "X, y = make_moons(400, noise=0.075)\n",
        "X_test, y_test = make_moons(400, noise=0.075)\n",
        "best_acc = 0\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([\n",
        "      Linear(2, 64),\n",
        "      ReLU(),\n",
        "      Linear(64, 64),\n",
        "      ReLU(),\n",
        "      Linear(64, 2)\n",
        "    ])\n",
        "    p.fit(X, y)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.9225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMDJM4qFQuvT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07fcc9d4-626e-480b-d309-0eafe172025d"
      },
      "source": [
        "X, y = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
        "best_acc = 0\n",
        "for _ in range(25):\n",
        "    p = MLPClassifier([\n",
        "      Linear(2, 64),\n",
        "      ReLU(),\n",
        "      Linear(64, 64),\n",
        "      ReLU(),\n",
        "      Linear(64, 3)\n",
        "    ])\n",
        "    p.fit(X, y)\n",
        "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
        "print(\"Accuracy\", best_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.9425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPbVTFnMQuvW"
      },
      "source": [
        "## PyTorch\n",
        "\n",
        "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
        "\n",
        "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV0mJLu-QuvX"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUC_QqpAQuva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fb81ba-f2fc-45dd-fdfc-29fa589a6929"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "t = transforms.ToTensor()\n",
        "\n",
        "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
        "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
        "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
        "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGmpjcFfQuvd"
      },
      "source": [
        "### Задание 4 (3 балла)\n",
        "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
        "\n",
        "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
        "\n",
        "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
        "\n",
        "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sRmTKwKQuve"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 10, 5)\n",
        "        self.mp = nn.MaxPool2d(2, 2)\n",
        "        self.fc = nn.Linear(10 * 5 * 5, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        in_size = x.size(0)\n",
        "        x = F.relu(self.mp(self.conv1(x)))\n",
        "        x = F.relu(self.mp(self.conv2(x)))\n",
        "        x = x.view(in_size, -1)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x)\n",
        "\n",
        "def calculate_loss(X: torch.Tensor, y: torch.Tensor, model: Model):\n",
        "  \n",
        "    predictions = model.forward(X)\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    return loss(predictions, y)\n",
        "\n",
        "    \"\"\"\n",
        "    Cчитает cross-entropy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : torch.Tensor\n",
        "        Данные для обучения.\n",
        "    y : torch.Tensor\n",
        "        Метки классов.\n",
        "    model : Model\n",
        "        Модель, которую будем обучать.\n",
        "\n",
        "    \"\"\""
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAsLmkUqQuvh"
      },
      "source": [
        "Теперь обучим нашу модель. Для этого используем ранее созданные batch loader'ы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5G8iMCeQuvh"
      },
      "source": [
        "def train(model, epochs=100):\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    for i in range(epochs):\n",
        "        #Train\n",
        "        loss_mean = 0\n",
        "        elements = 0\n",
        "        for X, y in iter(train_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        train_losses.append(loss_mean / elements)\n",
        "        #Test\n",
        "        loss_mean = 0 \n",
        "        elements = 0\n",
        "        for X, y in iter(test_loader):\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            loss = calculate_loss(X, y, model)\n",
        "            loss_mean += loss.item() * len(X)\n",
        "            elements += len(X)\n",
        "        test_losses.append(loss_mean / elements)\n",
        "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
        "    return train_losses, test_losses"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmD9eWJOQuvl",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63cd3cf-e987-45d8-85dc-01e83f4f4ad1"
      },
      "source": [
        "model = Model().to(device)\n",
        "train_l, test_l = train(model)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Train loss 2.135299001045227 | Test loss 1.9589323875427247\n",
            "Epoch 1 | Train loss 1.9040174471282958 | Test loss 1.852429295349121\n",
            "Epoch 2 | Train loss 1.812948392829895 | Test loss 1.76559604473114\n",
            "Epoch 3 | Train loss 1.7284419163131715 | Test loss 1.682737523651123\n",
            "Epoch 4 | Train loss 1.6521992755889892 | Test loss 1.615864907836914\n",
            "Epoch 5 | Train loss 1.599570605506897 | Test loss 1.5709214593887328\n",
            "Epoch 6 | Train loss 1.5563262784194947 | Test loss 1.5479534526824952\n",
            "Epoch 7 | Train loss 1.5303230350112915 | Test loss 1.5164154293060303\n",
            "Epoch 8 | Train loss 1.508492887763977 | Test loss 1.4986480430603026\n",
            "Epoch 9 | Train loss 1.489133256263733 | Test loss 1.484222819519043\n",
            "Epoch 10 | Train loss 1.4793716778945922 | Test loss 1.4800969116210938\n",
            "Epoch 11 | Train loss 1.4658430583572388 | Test loss 1.460766978263855\n",
            "Epoch 12 | Train loss 1.4561043569946288 | Test loss 1.45675638256073\n",
            "Epoch 13 | Train loss 1.4434335451889038 | Test loss 1.4488028926849366\n",
            "Epoch 14 | Train loss 1.439066555557251 | Test loss 1.4554563957214355\n",
            "Epoch 15 | Train loss 1.4310294607925416 | Test loss 1.4519949010848998\n",
            "Epoch 16 | Train loss 1.4295784285354614 | Test loss 1.446808420562744\n",
            "Epoch 17 | Train loss 1.4135644272232055 | Test loss 1.4180302936553955\n",
            "Epoch 18 | Train loss 1.4069494511413574 | Test loss 1.4084702392578126\n",
            "Epoch 19 | Train loss 1.3999813354873658 | Test loss 1.4140458124160766\n",
            "Epoch 20 | Train loss 1.3973883794784545 | Test loss 1.3995764764785767\n",
            "Epoch 21 | Train loss 1.3915887566757201 | Test loss 1.3941077527999879\n",
            "Epoch 22 | Train loss 1.3836671586227416 | Test loss 1.389288705444336\n",
            "Epoch 23 | Train loss 1.3760794189453125 | Test loss 1.383452589416504\n",
            "Epoch 24 | Train loss 1.3735313475418092 | Test loss 1.3771089849472047\n",
            "Epoch 25 | Train loss 1.3752232746887207 | Test loss 1.3816579223632812\n",
            "Epoch 26 | Train loss 1.3637248975753784 | Test loss 1.377892674255371\n",
            "Epoch 27 | Train loss 1.3572180837249757 | Test loss 1.3711824991226196\n",
            "Epoch 28 | Train loss 1.355002512550354 | Test loss 1.3704542720794677\n",
            "Epoch 29 | Train loss 1.3526466972732545 | Test loss 1.359055260848999\n",
            "Epoch 30 | Train loss 1.3481063868713379 | Test loss 1.3509447959899903\n",
            "Epoch 31 | Train loss 1.3391646603775025 | Test loss 1.3447541025161742\n",
            "Epoch 32 | Train loss 1.3380390444946288 | Test loss 1.3416911853790283\n",
            "Epoch 33 | Train loss 1.3306273544692993 | Test loss 1.3455101118087769\n",
            "Epoch 34 | Train loss 1.3276063515853882 | Test loss 1.3414785276412964\n",
            "Epoch 35 | Train loss 1.3252599530029296 | Test loss 1.348616456413269\n",
            "Epoch 36 | Train loss 1.321450214881897 | Test loss 1.3409349241256714\n",
            "Epoch 37 | Train loss 1.31566146900177 | Test loss 1.3488590684890747\n",
            "Epoch 38 | Train loss 1.3187113300704956 | Test loss 1.3310504013061524\n",
            "Epoch 39 | Train loss 1.3122184293746948 | Test loss 1.3264424394607544\n",
            "Epoch 40 | Train loss 1.3080477238845825 | Test loss 1.3284192657470704\n",
            "Epoch 41 | Train loss 1.3092649440383912 | Test loss 1.3204386211395263\n",
            "Epoch 42 | Train loss 1.3065189850997925 | Test loss 1.313981753540039\n",
            "Epoch 43 | Train loss 1.2969876821899413 | Test loss 1.306060897254944\n",
            "Epoch 44 | Train loss 1.2962397609710694 | Test loss 1.3188687660217284\n",
            "Epoch 45 | Train loss 1.2971772242736817 | Test loss 1.304351368522644\n",
            "Epoch 46 | Train loss 1.2893245220184326 | Test loss 1.3067796743392945\n",
            "Epoch 47 | Train loss 1.2862551639556885 | Test loss 1.2993423093795777\n",
            "Epoch 48 | Train loss 1.2828434212875366 | Test loss 1.2998230545043945\n",
            "Epoch 49 | Train loss 1.280398911895752 | Test loss 1.2949565677642823\n",
            "Epoch 50 | Train loss 1.2793130306625367 | Test loss 1.2916745582580567\n",
            "Epoch 51 | Train loss 1.2756680257415771 | Test loss 1.2851847806930543\n",
            "Epoch 52 | Train loss 1.2726878273010254 | Test loss 1.2863870477676391\n",
            "Epoch 53 | Train loss 1.2686227864456177 | Test loss 1.281230952835083\n",
            "Epoch 54 | Train loss 1.2696635527420044 | Test loss 1.2886123025894165\n",
            "Epoch 55 | Train loss 1.2637217033004762 | Test loss 1.277580598449707\n",
            "Epoch 56 | Train loss 1.2625115753173828 | Test loss 1.2724175397872926\n",
            "Epoch 57 | Train loss 1.2608125772857666 | Test loss 1.2893032602310182\n",
            "Epoch 58 | Train loss 1.2576221939086913 | Test loss 1.2703497472763061\n",
            "Epoch 59 | Train loss 1.255852673072815 | Test loss 1.2646144323349\n",
            "Epoch 60 | Train loss 1.2543795540237426 | Test loss 1.2688588256835938\n",
            "Epoch 61 | Train loss 1.256852587623596 | Test loss 1.2671246114730834\n",
            "Epoch 62 | Train loss 1.2481028008651733 | Test loss 1.2629134256362915\n",
            "Epoch 63 | Train loss 1.2447281450271606 | Test loss 1.262495838356018\n",
            "Epoch 64 | Train loss 1.2450624941253663 | Test loss 1.2560095897674561\n",
            "Epoch 65 | Train loss 1.2428519437408447 | Test loss 1.269617795753479\n",
            "Epoch 66 | Train loss 1.2405522101211548 | Test loss 1.2517383878707886\n",
            "Epoch 67 | Train loss 1.2409387617111205 | Test loss 1.2505301364898682\n",
            "Epoch 68 | Train loss 1.237114984703064 | Test loss 1.2549581632614135\n",
            "Epoch 69 | Train loss 1.2341874689483643 | Test loss 1.2696648942947388\n",
            "Epoch 70 | Train loss 1.2329527921676635 | Test loss 1.2473779008865356\n",
            "Epoch 71 | Train loss 1.2309862406158447 | Test loss 1.24853279838562\n",
            "Epoch 72 | Train loss 1.224776810874939 | Test loss 1.2425789525985718\n",
            "Epoch 73 | Train loss 1.2263434371185302 | Test loss 1.2510727670669555\n",
            "Epoch 74 | Train loss 1.2244612915420532 | Test loss 1.2459426986694335\n",
            "Epoch 75 | Train loss 1.2210257954406738 | Test loss 1.2355608291625977\n",
            "Epoch 76 | Train loss 1.2266152593612671 | Test loss 1.243053116798401\n",
            "Epoch 77 | Train loss 1.2208809866714478 | Test loss 1.240675157546997\n",
            "Epoch 78 | Train loss 1.2195979885482788 | Test loss 1.2415920991897582\n",
            "Epoch 79 | Train loss 1.2129597074890137 | Test loss 1.232938730621338\n",
            "Epoch 80 | Train loss 1.2136451577377319 | Test loss 1.238523727798462\n",
            "Epoch 81 | Train loss 1.2143349118804931 | Test loss 1.226141508102417\n",
            "Epoch 82 | Train loss 1.210639740409851 | Test loss 1.2371329223632812\n",
            "Epoch 83 | Train loss 1.206389528579712 | Test loss 1.2272539291381837\n",
            "Epoch 84 | Train loss 1.2035261352157594 | Test loss 1.2286827547073365\n",
            "Epoch 85 | Train loss 1.2097947315597535 | Test loss 1.222625901222229\n",
            "Epoch 86 | Train loss 1.2055105276489257 | Test loss 1.223195932006836\n",
            "Epoch 87 | Train loss 1.2028375252151489 | Test loss 1.2229752109527587\n",
            "Epoch 88 | Train loss 1.1986613528823853 | Test loss 1.2199768951416015\n",
            "Epoch 89 | Train loss 1.1964542864608765 | Test loss 1.215568489074707\n",
            "Epoch 90 | Train loss 1.193043201599121 | Test loss 1.2204130952835084\n",
            "Epoch 91 | Train loss 1.195133363456726 | Test loss 1.216773837852478\n",
            "Epoch 92 | Train loss 1.192653811454773 | Test loss 1.2182240510940552\n",
            "Epoch 93 | Train loss 1.1919303254318236 | Test loss 1.2158016382217407\n",
            "Epoch 94 | Train loss 1.1927630899047852 | Test loss 1.2193532247543335\n",
            "Epoch 95 | Train loss 1.1908188192367555 | Test loss 1.2138340494155884\n",
            "Epoch 96 | Train loss 1.189091078300476 | Test loss 1.2103505895614624\n",
            "Epoch 97 | Train loss 1.186118228187561 | Test loss 1.225620785331726\n",
            "Epoch 98 | Train loss 1.186448736152649 | Test loss 1.2096381368637086\n",
            "Epoch 99 | Train loss 1.1846515240097046 | Test loss 1.2065949699401854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJNAuHjNQuvn"
      },
      "source": [
        "Построим график функции потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6OEGqriQuvo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "588635a9-6925-486f-dd05-885ca2730d8f"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
        "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miUxg0bDQuvs"
      },
      "source": [
        "И, наконец, посчитаем метрики"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXSOJFI8Quvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba139a0d-8380-4d28-a111-53e6213abbe2"
      },
      "source": [
        "true_positive = np.zeros(10)\n",
        "true_negative = np.zeros(10)\n",
        "false_positive = np.zeros(10)\n",
        "false_negative = np.zeros(10)\n",
        "accuracy = 0\n",
        "ctn = 0\n",
        "for X, y in iter(test_loader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X).max(dim=1)[1]\n",
        "    for i in range(10):\n",
        "        for pred, real in zip(y_pred, y):\n",
        "            if real == i:\n",
        "                if pred == real:\n",
        "                    true_positive[i] += 1\n",
        "                else:\n",
        "                    false_negative[i] += 1\n",
        "            else:\n",
        "                if pred == i:\n",
        "                    false_positive[i] += 1\n",
        "                else:\n",
        "                    true_negative[i] += 1\n",
        "            \n",
        "    accuracy += torch.sum(y_pred == y).item()\n",
        "    ctn += len(y)\n",
        "print(\"Overall accuracy\", accuracy / ctn)\n",
        "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
        "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
        "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
        "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Overall accuracy 0.5783\n",
            "Precision [0.6502994  0.71629779 0.48598131 0.44814341 0.48771611 0.51015532\n",
            " 0.57164988 0.60329068 0.60993485 0.6833713 ]\n",
            "Recall [0.543 0.712 0.468 0.35  0.536 0.427 0.738 0.66  0.749 0.6  ]\n",
            "Mean Precision 0.5766840036429937\n",
            "Mean Recall 0.5782999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKA-j4rIQuvv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}